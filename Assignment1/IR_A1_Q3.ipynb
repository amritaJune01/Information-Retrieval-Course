{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c64cab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86da33db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cranfield1223</td>\n",
       "      <td>['inviscid-incompressible-flow', 'theory', 'st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cranfield1011</td>\n",
       "      <td>['free-flight', 'measurements', 'static', 'dyn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cranfield0795</td>\n",
       "      <td>['operation', 'npl', '18in', 'x', '14in', 'win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cranfield0553</td>\n",
       "      <td>['ablation', 'glassy', 'materials', 'around', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cranfield0761</td>\n",
       "      <td>['buckling', 'sandwich', 'normal', 'pressure',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fname                                            content\n",
       "0  cranfield1223  ['inviscid-incompressible-flow', 'theory', 'st...\n",
       "1  cranfield1011  ['free-flight', 'measurements', 'static', 'dyn...\n",
       "2  cranfield0795  ['operation', 'npl', '18in', 'x', '14in', 'win...\n",
       "3  cranfield0553  ['ablation', 'glassy', 'materials', 'around', ...\n",
       "4  cranfield0761  ['buckling', 'sandwich', 'normal', 'pressure',..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final_df.csv')\n",
    "\n",
    "df.columns = ['fname', 'content']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b2bb4a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create bigram inverted index\n",
    "bigrams = dict()\n",
    "for row in range(len(df)):\n",
    "    doc = ast.literal_eval(df['content'][row])  #throw out the contents of string\n",
    "    for doc_index in range(len(doc)-1):\n",
    "        if (doc[doc_index],doc[doc_index+1]) not in bigrams:\n",
    "            bigrams[(doc[doc_index],doc[doc_index+1])] = set([df['fname'][row]])\n",
    "        else:\n",
    "            bigrams[(doc[doc_index],doc[doc_index+1])].add(df['fname'][row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e577af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cranfield0012',\n",
       " 'cranfield0021',\n",
       " 'cranfield0022',\n",
       " 'cranfield0023',\n",
       " 'cranfield0024',\n",
       " 'cranfield0029',\n",
       " 'cranfield0036',\n",
       " 'cranfield0037',\n",
       " 'cranfield0045',\n",
       " 'cranfield0049',\n",
       " 'cranfield0054',\n",
       " 'cranfield0055',\n",
       " 'cranfield0061',\n",
       " 'cranfield0062',\n",
       " 'cranfield0072',\n",
       " 'cranfield0074',\n",
       " 'cranfield0077',\n",
       " 'cranfield0081',\n",
       " 'cranfield0082',\n",
       " 'cranfield0084',\n",
       " 'cranfield0088',\n",
       " 'cranfield0089',\n",
       " 'cranfield0098',\n",
       " 'cranfield0101',\n",
       " 'cranfield0102',\n",
       " 'cranfield0120',\n",
       " 'cranfield0123',\n",
       " 'cranfield0142',\n",
       " 'cranfield0144',\n",
       " 'cranfield0145',\n",
       " 'cranfield0240',\n",
       " 'cranfield0260',\n",
       " 'cranfield0267',\n",
       " 'cranfield0268',\n",
       " 'cranfield0269',\n",
       " 'cranfield0270',\n",
       " 'cranfield0274',\n",
       " 'cranfield0283',\n",
       " 'cranfield0294',\n",
       " 'cranfield0295',\n",
       " 'cranfield0303',\n",
       " 'cranfield0305',\n",
       " 'cranfield0306',\n",
       " 'cranfield0310',\n",
       " 'cranfield0314',\n",
       " 'cranfield0325',\n",
       " 'cranfield0329',\n",
       " 'cranfield0333',\n",
       " 'cranfield0339',\n",
       " 'cranfield0343',\n",
       " 'cranfield0344',\n",
       " 'cranfield0347',\n",
       " 'cranfield0348',\n",
       " 'cranfield0352',\n",
       " 'cranfield0353',\n",
       " 'cranfield0364',\n",
       " 'cranfield0366',\n",
       " 'cranfield0378',\n",
       " 'cranfield0383',\n",
       " 'cranfield0387',\n",
       " 'cranfield0395',\n",
       " 'cranfield0396',\n",
       " 'cranfield0398',\n",
       " 'cranfield0435',\n",
       " 'cranfield0436',\n",
       " 'cranfield0437',\n",
       " 'cranfield0438',\n",
       " 'cranfield0489',\n",
       " 'cranfield0493',\n",
       " 'cranfield0509',\n",
       " 'cranfield0522',\n",
       " 'cranfield0524',\n",
       " 'cranfield0538',\n",
       " 'cranfield0539',\n",
       " 'cranfield0546',\n",
       " 'cranfield0549',\n",
       " 'cranfield0550',\n",
       " 'cranfield0553',\n",
       " 'cranfield0554',\n",
       " 'cranfield0555',\n",
       " 'cranfield0559',\n",
       " 'cranfield0560',\n",
       " 'cranfield0564',\n",
       " 'cranfield0565',\n",
       " 'cranfield0566',\n",
       " 'cranfield0571',\n",
       " 'cranfield0575',\n",
       " 'cranfield0576',\n",
       " 'cranfield0584',\n",
       " 'cranfield0585',\n",
       " 'cranfield0606',\n",
       " 'cranfield0623',\n",
       " 'cranfield0625',\n",
       " 'cranfield0635',\n",
       " 'cranfield0645',\n",
       " 'cranfield0646',\n",
       " 'cranfield0651',\n",
       " 'cranfield0655',\n",
       " 'cranfield0661',\n",
       " 'cranfield0662',\n",
       " 'cranfield0666',\n",
       " 'cranfield0668',\n",
       " 'cranfield0670',\n",
       " 'cranfield0689',\n",
       " 'cranfield0690',\n",
       " 'cranfield0754',\n",
       " 'cranfield0767',\n",
       " 'cranfield0784',\n",
       " 'cranfield0789',\n",
       " 'cranfield0861',\n",
       " 'cranfield0869',\n",
       " 'cranfield0872',\n",
       " 'cranfield0873',\n",
       " 'cranfield0959',\n",
       " 'cranfield0962',\n",
       " 'cranfield0963',\n",
       " 'cranfield0979',\n",
       " 'cranfield0981',\n",
       " 'cranfield0983',\n",
       " 'cranfield1002',\n",
       " 'cranfield1099',\n",
       " 'cranfield1104',\n",
       " 'cranfield1106',\n",
       " 'cranfield1107',\n",
       " 'cranfield1147',\n",
       " 'cranfield1159',\n",
       " 'cranfield1161',\n",
       " 'cranfield1185',\n",
       " 'cranfield1191',\n",
       " 'cranfield1192',\n",
       " 'cranfield1204',\n",
       " 'cranfield1213',\n",
       " 'cranfield1215',\n",
       " 'cranfield1217',\n",
       " 'cranfield1222',\n",
       " 'cranfield1226',\n",
       " 'cranfield1258',\n",
       " 'cranfield1263',\n",
       " 'cranfield1264',\n",
       " 'cranfield1268',\n",
       " 'cranfield1281',\n",
       " 'cranfield1282',\n",
       " 'cranfield1300',\n",
       " 'cranfield1307',\n",
       " 'cranfield1348',\n",
       " 'cranfield1355',\n",
       " 'cranfield1366',\n",
       " 'cranfield1381',\n",
       " 'cranfield1386',\n",
       " 'cranfield1393',\n",
       " 'cranfield1394',\n",
       " 'cranfield1395'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams[('heat', 'transfer')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bc64d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85921"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1483cf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open('bigrams.pickle', 'wb') as handle:\n",
    "#     pickle.dump(bigrams, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a79d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('bigrams.pickle', 'rb') as handle:\n",
    "#     bigrams = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70a22220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_index = dict()\n",
    "# for row in range(len(df)):\n",
    "#     doc = ast.literal_eval(df['content'][row])\n",
    "#     for doc_index in range(len(doc)):\n",
    "#         if doc[doc_index] not in pos_index:   #word 'be' itself seen first time\n",
    "#             pos_index[doc[doc_index]] = {df['fname'][row]:set([doc_index+1])}\n",
    "#         else:                         #word 'be' present but seen in a particular 'docID' for the first time\n",
    "#             try:\n",
    "#                 pos_index[doc[doc_index]][df['fname'][row]].add(doc_index+1)\n",
    "#             except:\n",
    "#                 pos_index[doc[doc_index]][df['fname'][row]] = set([doc_index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd2bc460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create positional inverted index\n",
    "pos_index = dict() \n",
    "for row in range(len(df)):\n",
    "    doc = ast.literal_eval(df['content'][row])\n",
    "    for doc_index in range(len(doc)):\n",
    "        if doc[doc_index] not in pos_index:   #word 'be' itself seen first time\n",
    "            pos_index[doc[doc_index]] = {df['fname'][row]:list([doc_index+1])}\n",
    "        else:                         #word 'be' present but seen in a particular 'docID' for the first time\n",
    "            try:\n",
    "                pos_index[doc[doc_index]][df['fname'][row]].append(doc_index+1)\n",
    "            except:\n",
    "                pos_index[doc[doc_index]][df['fname'][row]] = list([doc_index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9238cfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cranfield1223': [26],\n",
       " 'cranfield0137': [16],\n",
       " 'cranfield1212': [18],\n",
       " 'cranfield0969': [25, 48],\n",
       " 'cranfield0993': [2, 6, 24, 56, 65, 97, 117, 119],\n",
       " 'cranfield0994': [17, 29],\n",
       " 'cranfield0335': [47],\n",
       " 'cranfield0904': [80],\n",
       " 'cranfield0131': [2, 9, 23, 56, 79, 92, 97, 115, 167],\n",
       " 'cranfield0961': [4, 15, 80, 90],\n",
       " 'cranfield0350': [2, 10, 28, 31, 37, 43],\n",
       " 'cranfield0992': [3, 19, 59, 74, 82, 114, 118, 132, 160, 167],\n",
       " 'cranfield1350': [2, 13, 30, 56, 64],\n",
       " 'cranfield0282': [1, 16, 34, 66, 68, 76, 108],\n",
       " 'cranfield0086': [36, 50],\n",
       " 'cranfield0624': [40, 55],\n",
       " 'cranfield0640': [4, 10],\n",
       " 'cranfield1101': [20],\n",
       " 'cranfield1351': [4, 24, 90, 98, 122],\n",
       " 'cranfield1374': [14],\n",
       " 'cranfield0636': [27, 43],\n",
       " 'cranfield0290': [19, 54],\n",
       " 'cranfield0696': [88, 121, 155, 163],\n",
       " 'cranfield1375': [4, 28],\n",
       " 'cranfield0697': [15, 32, 50, 55, 91],\n",
       " 'cranfield0176': [7, 25, 30, 36, 42, 58, 64],\n",
       " 'cranfield0182': [12],\n",
       " 'cranfield1265': [3, 12, 49, 56, 72, 84],\n",
       " 'cranfield0171': [35],\n",
       " 'cranfield0727': [32],\n",
       " 'cranfield0972': [6, 23, 47, 56, 70, 99],\n",
       " 'cranfield1061': [5, 16, 145],\n",
       " 'cranfield0729': [69],\n",
       " 'cranfield0773': [116],\n",
       " 'cranfield1209': [57, 127],\n",
       " 'cranfield1093': [4, 11, 22, 38],\n",
       " 'cranfield0726': [10, 61],\n",
       " 'cranfield0973': [4, 19, 45, 53],\n",
       " 'cranfield0721': [4, 13, 61, 97, 113, 124, 140, 159, 163, 200, 204, 206, 259],\n",
       " 'cranfield0177': [35, 42, 46, 53, 57, 61, 70],\n",
       " 'cranfield0772': [13, 31],\n",
       " 'cranfield0911': [8, 23],\n",
       " 'cranfield0997': [37, 43, 47, 49, 53, 64, 66, 83, 92, 98, 104],\n",
       " 'cranfield0908': [78, 91],\n",
       " 'cranfield0330': [56],\n",
       " 'cranfield1211': [15],\n",
       " 'cranfield0991': [9, 29, 49, 64, 73, 80, 94, 98, 108, 109, 118],\n",
       " 'cranfield1244': [4, 12, 17, 208, 216],\n",
       " 'cranfield0103': [6, 34, 47],\n",
       " 'cranfield0909': [2, 15, 28],\n",
       " 'cranfield0040': [14],\n",
       " 'cranfield1195': [10,\n",
       "  16,\n",
       "  23,\n",
       "  27,\n",
       "  29,\n",
       "  41,\n",
       "  46,\n",
       "  54,\n",
       "  67,\n",
       "  74,\n",
       "  82,\n",
       "  95,\n",
       "  115,\n",
       "  127,\n",
       "  133,\n",
       "  151],\n",
       " 'cranfield0243': [7, 12, 47],\n",
       " 'cranfield0076': [16],\n",
       " 'cranfield0219': [6, 12, 27, 63, 81],\n",
       " 'cranfield1151': [31],\n",
       " 'cranfield0245': [3, 17, 25, 38, 49, 52, 66, 68, 84],\n",
       " 'cranfield1352': [13, 28, 32, 45, 57, 62, 67, 112, 116, 122],\n",
       " 'cranfield0218': [9, 20, 43, 63, 92, 96, 101],\n",
       " 'cranfield0220': [19],\n",
       " 'cranfield0650': [12, 21],\n",
       " 'cranfield0692': [2, 24, 40, 64, 77, 92],\n",
       " 'cranfield0695': [6,\n",
       "  9,\n",
       "  51,\n",
       "  53,\n",
       "  57,\n",
       "  59,\n",
       "  62,\n",
       "  68,\n",
       "  71,\n",
       "  72,\n",
       "  82,\n",
       "  121,\n",
       "  123,\n",
       "  126,\n",
       "  166,\n",
       "  189,\n",
       "  200],\n",
       " 'cranfield0453': [80, 93, 99],\n",
       " 'cranfield0860': [11],\n",
       " 'cranfield0409': [10, 29, 31],\n",
       " 'cranfield0694': [8, 29, 50],\n",
       " 'cranfield0693': [2, 27, 47, 67],\n",
       " 'cranfield0007': [16],\n",
       " 'cranfield1371': [52],\n",
       " 'cranfield1349': [4, 39, 58],\n",
       " 'cranfield0746': [68],\n",
       " 'cranfield1232': [2, 8, 22, 27, 35],\n",
       " 'cranfield0126': [54],\n",
       " 'cranfield0172': [62, 85],\n",
       " 'cranfield1292': [2, 13, 67, 102, 134],\n",
       " 'cranfield0971': [5, 23, 49, 60],\n",
       " 'cranfield1098': [23, 70],\n",
       " 'cranfield0129': [6, 19, 50, 58, 61, 82],\n",
       " 'cranfield0946': [6, 18, 44, 51, 72, 93, 104, 189],\n",
       " 'cranfield0519': [7, 11, 18, 25, 36, 48, 53, 90, 99],\n",
       " 'cranfield0722': [5, 21, 39],\n",
       " 'cranfield0174': [5, 24, 27, 44, 68, 72, 89, 101, 120, 156, 162],\n",
       " 'cranfield0341': [9],\n",
       " 'cranfield0173': [3, 18, 35, 47, 79, 85, 96, 99, 116, 119, 147, 152],\n",
       " 'cranfield0725': [5, 18],\n",
       " 'cranfield0970': [7, 24, 93]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_index['jet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dd84e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9709"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b530420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('pos_index.pickle', 'wb') as handle:\n",
    "#     pickle.dump(pos_index, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2423a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('pos_index.pickle', 'rb') as handle:\n",
    "#     pos_index = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6345c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even with a limited number of unique words in the corpus, i.e. the vocab used in the positional index, \n",
    "#very large no. of  pairs are possible, of which quite no. of them could be present in corpus as bigrams;\n",
    "#making a larger dictionary, with a larger size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2469ba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "punc = [ p for p in punctuations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8228ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pre-process query\n",
    "def preprocess(query):\n",
    "    query = query.lower()\n",
    "    tokens = word_tokenize(query)\n",
    "    remove_stop = [t for t in tokens if not t in stopwords.words(\"english\")]\n",
    "    remove_punc = [t for t in remove_stop if t not in punc]\n",
    "    res = [ t.strip() for t in remove_punc if len(t.strip()) != 0]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "876ac8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_docs(query):\n",
    "    doc_set = set()\n",
    "    for i in range(len(query)-1):\n",
    "        if (query[i], query[i+1]) in bigrams:\n",
    "            if i==0:\n",
    "                doc_set = bigrams[(query[i], query[i+1])].copy()\n",
    "            else:\n",
    "                doc_set = doc_set.intersection(bigrams[(query[i], query[i+1])])\n",
    "    return len(doc_set), sorted(list(doc_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d87be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment(temp_dict):  #increment position of each doc by 1 \n",
    "    for doc_list in temp_dict:\n",
    "        postings_list = temp_dict[doc_list].copy()\n",
    "        postings_list = [sum(x) for x in zip(postings_list, [1]*len(postings_list))]\n",
    "        temp_dict[doc_list] = postings_list\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54bd8d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(dict1, dict2):  #find the set of docs where the next word(dict 2) comes just after the current seen phrase(dict1)\n",
    "    new_dict = {}\n",
    "    for doc_a in dict1:\n",
    "        try:\n",
    "           new_dict[doc_a] = sorted(list(set(dict1[doc_a]).intersection(set(dict2[doc_a]))))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ac04a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh(temp1):  #remove those docs(keys in the dict) which have 0 sized postings lists - remove the docs which don't have the phrase within them in intermediate \n",
    "    temp2 = dict()\n",
    "    for doc in temp1:\n",
    "        if len(temp1[doc])!= 0:\n",
    "            temp2[doc] = temp1[doc]\n",
    "            \n",
    "    return temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f482e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_docs(query):  #solve queries using positional inverted indexes\n",
    "    for (i, word) in enumerate(query):\n",
    "        if word not in pos_index:\n",
    "            return 0, list()\n",
    "        else:\n",
    "            temp_dict = pos_index[word].copy()\n",
    "            if i==0:\n",
    "                temp_dict = increment(temp_dict)\n",
    "                pos_dict = temp_dict                \n",
    "            else:\n",
    "                pos_dict = intersect(pos_dict, temp_dict)\n",
    "                pos_dict = refresh(pos_dict)\n",
    "                pos_dict = increment(pos_dict)\n",
    "    \n",
    "\n",
    "    return len(pos_dict), list(pos_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0437de48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input[['downstream', 'roughness', 'causes'], ['including', 'gust', 'response']]\n",
      "\n",
      "Number of documents retrieved for query 1 using bigram inverted index:1 \n",
      "Names of documents retrieved for query 1 using bigram inverted index: ['cranfield0933']\n",
      "Number of documents retrieved for query 1 using positional inverted index:1 \n",
      "Names of documents retrieved for query 1 using positional inverted index: ['cranfield0933']\n",
      "\n",
      "Number of documents retrieved for query 2 using bigram inverted index:1 \n",
      "Names of documents retrieved for query 2 using bigram inverted index: ['cranfield0014']\n",
      "Number of documents retrieved for query 2 using positional inverted index:1 \n",
      "Names of documents retrieved for query 2 using positional inverted index: ['cranfield0014']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = int(input(\"Enter number of queries to execute: \"))\n",
    "query_list=[]\n",
    "for i in range(n):\n",
    "    query = input()\n",
    "    query = preprocess(query)\n",
    "    query_list.append(query)\n",
    "print(f'Input{query_list}\\n')\n",
    "for i in range(n):\n",
    "    \n",
    "    count_files, files = bigram_docs(query_list[i])\n",
    "    print(f'Number of documents retrieved for query {i+1} using bigram inverted index:{count_files} \\nNames of documents retrieved for query {i+1} using bigram inverted index: {files}')\n",
    "\n",
    "    count_files, files = positional_docs(query_list[i])\n",
    "    print(f'Number of documents retrieved for query {i+1} using positional inverted index:{count_files} \\nNames of documents retrieved for query {i+1} using positional inverted index: {files}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d5e19e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
